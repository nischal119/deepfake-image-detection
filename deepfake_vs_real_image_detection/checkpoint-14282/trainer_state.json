{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 14282,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.014003640946646127,
      "grad_norm": 4.368112087249756,
      "learning_rate": 0.00015944912872400228,
      "loss": 0.2641,
      "step": 100
    },
    {
      "epoch": 0.028007281893292255,
      "grad_norm": 1.5969938039779663,
      "learning_rate": 0.0001583249016301293,
      "loss": 0.3354,
      "step": 200
    },
    {
      "epoch": 0.04201092283993838,
      "grad_norm": 6.899086952209473,
      "learning_rate": 0.00015720067453625633,
      "loss": 0.2175,
      "step": 300
    },
    {
      "epoch": 0.05601456378658451,
      "grad_norm": 0.6165607571601868,
      "learning_rate": 0.00015607644744238336,
      "loss": 0.224,
      "step": 400
    },
    {
      "epoch": 0.07001820473323064,
      "grad_norm": 2.906463146209717,
      "learning_rate": 0.0001549522203485104,
      "loss": 0.2484,
      "step": 500
    },
    {
      "epoch": 0.08402184567987676,
      "grad_norm": 2.427863597869873,
      "learning_rate": 0.00015382799325463744,
      "loss": 0.2533,
      "step": 600
    },
    {
      "epoch": 0.0980254866265229,
      "grad_norm": 1.3262025117874146,
      "learning_rate": 0.0001527037661607645,
      "loss": 0.2036,
      "step": 700
    },
    {
      "epoch": 0.11202912757316902,
      "grad_norm": 3.447567939758301,
      "learning_rate": 0.00015157953906689151,
      "loss": 0.2377,
      "step": 800
    },
    {
      "epoch": 0.12603276851981515,
      "grad_norm": 1.8397232294082642,
      "learning_rate": 0.00015045531197301857,
      "loss": 0.2547,
      "step": 900
    },
    {
      "epoch": 0.1400364094664613,
      "grad_norm": 5.242388725280762,
      "learning_rate": 0.0001493310848791456,
      "loss": 0.1659,
      "step": 1000
    },
    {
      "epoch": 0.15404005041310742,
      "grad_norm": 1.384377121925354,
      "learning_rate": 0.00014820685778527265,
      "loss": 0.2491,
      "step": 1100
    },
    {
      "epoch": 0.16804369135975353,
      "grad_norm": 2.73659348487854,
      "learning_rate": 0.00014708263069139967,
      "loss": 0.2174,
      "step": 1200
    },
    {
      "epoch": 0.18204733230639966,
      "grad_norm": 1.5621248483657837,
      "learning_rate": 0.0001459584035975267,
      "loss": 0.1882,
      "step": 1300
    },
    {
      "epoch": 0.1960509732530458,
      "grad_norm": 1.4345653057098389,
      "learning_rate": 0.00014483417650365375,
      "loss": 0.1978,
      "step": 1400
    },
    {
      "epoch": 0.21005461419969193,
      "grad_norm": 4.472506046295166,
      "learning_rate": 0.00014370994940978078,
      "loss": 0.1662,
      "step": 1500
    },
    {
      "epoch": 0.22405825514633804,
      "grad_norm": 0.5424849987030029,
      "learning_rate": 0.00014258572231590783,
      "loss": 0.1779,
      "step": 1600
    },
    {
      "epoch": 0.23806189609298417,
      "grad_norm": 0.1614929586648941,
      "learning_rate": 0.00014146149522203485,
      "loss": 0.1672,
      "step": 1700
    },
    {
      "epoch": 0.2520655370396303,
      "grad_norm": 2.6760072708129883,
      "learning_rate": 0.0001403372681281619,
      "loss": 0.1892,
      "step": 1800
    },
    {
      "epoch": 0.26606917798627644,
      "grad_norm": 0.49170246720314026,
      "learning_rate": 0.00013921304103428893,
      "loss": 0.1536,
      "step": 1900
    },
    {
      "epoch": 0.2800728189329226,
      "grad_norm": 1.2797709703445435,
      "learning_rate": 0.00013808881394041599,
      "loss": 0.2038,
      "step": 2000
    },
    {
      "epoch": 0.2940764598795687,
      "grad_norm": 3.5821373462677,
      "learning_rate": 0.000136964586846543,
      "loss": 0.167,
      "step": 2100
    },
    {
      "epoch": 0.30808010082621484,
      "grad_norm": 2.3619771003723145,
      "learning_rate": 0.00013584035975267004,
      "loss": 0.1873,
      "step": 2200
    },
    {
      "epoch": 0.3220837417728609,
      "grad_norm": 4.759986877441406,
      "learning_rate": 0.0001347161326587971,
      "loss": 0.1809,
      "step": 2300
    },
    {
      "epoch": 0.33608738271950706,
      "grad_norm": 7.20267391204834,
      "learning_rate": 0.00013359190556492412,
      "loss": 0.1324,
      "step": 2400
    },
    {
      "epoch": 0.3500910236661532,
      "grad_norm": 2.581861734390259,
      "learning_rate": 0.00013246767847105117,
      "loss": 0.1366,
      "step": 2500
    },
    {
      "epoch": 0.3640946646127993,
      "grad_norm": 0.16403457522392273,
      "learning_rate": 0.0001313434513771782,
      "loss": 0.153,
      "step": 2600
    },
    {
      "epoch": 0.37809830555944546,
      "grad_norm": 0.5097622871398926,
      "learning_rate": 0.00013021922428330525,
      "loss": 0.1564,
      "step": 2700
    },
    {
      "epoch": 0.3921019465060916,
      "grad_norm": 3.4056835174560547,
      "learning_rate": 0.00012909499718943227,
      "loss": 0.1689,
      "step": 2800
    },
    {
      "epoch": 0.4061055874527377,
      "grad_norm": 4.035326957702637,
      "learning_rate": 0.00012797077009555933,
      "loss": 0.151,
      "step": 2900
    },
    {
      "epoch": 0.42010922839938386,
      "grad_norm": 1.8516346216201782,
      "learning_rate": 0.00012684654300168635,
      "loss": 0.1632,
      "step": 3000
    },
    {
      "epoch": 0.43411286934603,
      "grad_norm": 2.872865915298462,
      "learning_rate": 0.00012572231590781338,
      "loss": 0.1523,
      "step": 3100
    },
    {
      "epoch": 0.4481165102926761,
      "grad_norm": 1.2979762554168701,
      "learning_rate": 0.00012459808881394043,
      "loss": 0.1547,
      "step": 3200
    },
    {
      "epoch": 0.4621201512393222,
      "grad_norm": 1.0252587795257568,
      "learning_rate": 0.00012347386172006746,
      "loss": 0.1377,
      "step": 3300
    },
    {
      "epoch": 0.47612379218596834,
      "grad_norm": 0.9193222522735596,
      "learning_rate": 0.0001223496346261945,
      "loss": 0.1768,
      "step": 3400
    },
    {
      "epoch": 0.4901274331326145,
      "grad_norm": 1.3854975700378418,
      "learning_rate": 0.00012122540753232153,
      "loss": 0.1576,
      "step": 3500
    },
    {
      "epoch": 0.5041310740792606,
      "grad_norm": 0.690541684627533,
      "learning_rate": 0.00012010118043844857,
      "loss": 0.1552,
      "step": 3600
    },
    {
      "epoch": 0.5181347150259067,
      "grad_norm": 0.7151167988777161,
      "learning_rate": 0.00011897695334457561,
      "loss": 0.1515,
      "step": 3700
    },
    {
      "epoch": 0.5321383559725529,
      "grad_norm": 1.926611304283142,
      "learning_rate": 0.00011785272625070265,
      "loss": 0.1828,
      "step": 3800
    },
    {
      "epoch": 0.546141996919199,
      "grad_norm": 2.807600975036621,
      "learning_rate": 0.00011672849915682969,
      "loss": 0.14,
      "step": 3900
    },
    {
      "epoch": 0.5601456378658451,
      "grad_norm": 2.372182846069336,
      "learning_rate": 0.00011560427206295672,
      "loss": 0.1541,
      "step": 4000
    },
    {
      "epoch": 0.5741492788124912,
      "grad_norm": 3.509732961654663,
      "learning_rate": 0.00011448004496908376,
      "loss": 0.1331,
      "step": 4100
    },
    {
      "epoch": 0.5881529197591374,
      "grad_norm": 0.7811975479125977,
      "learning_rate": 0.0001133558178752108,
      "loss": 0.123,
      "step": 4200
    },
    {
      "epoch": 0.6021565607057835,
      "grad_norm": 0.5803490877151489,
      "learning_rate": 0.00011223159078133783,
      "loss": 0.1271,
      "step": 4300
    },
    {
      "epoch": 0.6161602016524297,
      "grad_norm": 1.457497000694275,
      "learning_rate": 0.00011110736368746487,
      "loss": 0.1528,
      "step": 4400
    },
    {
      "epoch": 0.6301638425990758,
      "grad_norm": 12.120734214782715,
      "learning_rate": 0.00010998313659359191,
      "loss": 0.1467,
      "step": 4500
    },
    {
      "epoch": 0.6441674835457218,
      "grad_norm": 1.5219742059707642,
      "learning_rate": 0.00010885890949971895,
      "loss": 0.144,
      "step": 4600
    },
    {
      "epoch": 0.658171124492368,
      "grad_norm": 0.9649093151092529,
      "learning_rate": 0.00010773468240584599,
      "loss": 0.1159,
      "step": 4700
    },
    {
      "epoch": 0.6721747654390141,
      "grad_norm": 0.28838208317756653,
      "learning_rate": 0.00010661045531197303,
      "loss": 0.1425,
      "step": 4800
    },
    {
      "epoch": 0.6861784063856603,
      "grad_norm": 0.30922138690948486,
      "learning_rate": 0.00010548622821810006,
      "loss": 0.137,
      "step": 4900
    },
    {
      "epoch": 0.7001820473323064,
      "grad_norm": 0.7684023380279541,
      "learning_rate": 0.0001043620011242271,
      "loss": 0.1062,
      "step": 5000
    },
    {
      "epoch": 0.7141856882789526,
      "grad_norm": 0.028689319267868996,
      "learning_rate": 0.00010323777403035414,
      "loss": 0.1243,
      "step": 5100
    },
    {
      "epoch": 0.7281893292255986,
      "grad_norm": 2.2554032802581787,
      "learning_rate": 0.00010211354693648117,
      "loss": 0.1448,
      "step": 5200
    },
    {
      "epoch": 0.7421929701722448,
      "grad_norm": 3.6744375228881836,
      "learning_rate": 0.00010098931984260821,
      "loss": 0.1435,
      "step": 5300
    },
    {
      "epoch": 0.7561966111188909,
      "grad_norm": 5.3084306716918945,
      "learning_rate": 9.986509274873525e-05,
      "loss": 0.1248,
      "step": 5400
    },
    {
      "epoch": 0.770200252065537,
      "grad_norm": 3.8325188159942627,
      "learning_rate": 9.874086565486229e-05,
      "loss": 0.1173,
      "step": 5500
    },
    {
      "epoch": 0.7842038930121832,
      "grad_norm": 0.29439228773117065,
      "learning_rate": 9.761663856098933e-05,
      "loss": 0.1195,
      "step": 5600
    },
    {
      "epoch": 0.7982075339588293,
      "grad_norm": 0.22079795598983765,
      "learning_rate": 9.649241146711637e-05,
      "loss": 0.1196,
      "step": 5700
    },
    {
      "epoch": 0.8122111749054755,
      "grad_norm": 6.629029750823975,
      "learning_rate": 9.53681843732434e-05,
      "loss": 0.1202,
      "step": 5800
    },
    {
      "epoch": 0.8262148158521215,
      "grad_norm": 5.871932029724121,
      "learning_rate": 9.424395727937044e-05,
      "loss": 0.1262,
      "step": 5900
    },
    {
      "epoch": 0.8402184567987677,
      "grad_norm": 0.06453883647918701,
      "learning_rate": 9.311973018549748e-05,
      "loss": 0.1029,
      "step": 6000
    },
    {
      "epoch": 0.8542220977454138,
      "grad_norm": 7.787413597106934,
      "learning_rate": 9.199550309162451e-05,
      "loss": 0.1244,
      "step": 6100
    },
    {
      "epoch": 0.86822573869206,
      "grad_norm": 5.104393482208252,
      "learning_rate": 9.087127599775155e-05,
      "loss": 0.1141,
      "step": 6200
    },
    {
      "epoch": 0.8822293796387061,
      "grad_norm": 0.412631094455719,
      "learning_rate": 8.97470489038786e-05,
      "loss": 0.1096,
      "step": 6300
    },
    {
      "epoch": 0.8962330205853521,
      "grad_norm": 3.1261935234069824,
      "learning_rate": 8.862282181000563e-05,
      "loss": 0.1341,
      "step": 6400
    },
    {
      "epoch": 0.9102366615319983,
      "grad_norm": 6.555532455444336,
      "learning_rate": 8.749859471613267e-05,
      "loss": 0.1193,
      "step": 6500
    },
    {
      "epoch": 0.9242403024786444,
      "grad_norm": 0.42039212584495544,
      "learning_rate": 8.637436762225971e-05,
      "loss": 0.1056,
      "step": 6600
    },
    {
      "epoch": 0.9382439434252906,
      "grad_norm": 2.9941723346710205,
      "learning_rate": 8.525014052838674e-05,
      "loss": 0.1106,
      "step": 6700
    },
    {
      "epoch": 0.9522475843719367,
      "grad_norm": 3.5324695110321045,
      "learning_rate": 8.412591343451378e-05,
      "loss": 0.1185,
      "step": 6800
    },
    {
      "epoch": 0.9662512253185829,
      "grad_norm": 2.1971588134765625,
      "learning_rate": 8.300168634064082e-05,
      "loss": 0.1194,
      "step": 6900
    },
    {
      "epoch": 0.980254866265229,
      "grad_norm": 0.31982383131980896,
      "learning_rate": 8.187745924676785e-05,
      "loss": 0.1153,
      "step": 7000
    },
    {
      "epoch": 0.9942585072118751,
      "grad_norm": 1.0656616687774658,
      "learning_rate": 8.07532321528949e-05,
      "loss": 0.1193,
      "step": 7100
    },
    {
      "epoch": 1.0082621481585212,
      "grad_norm": 8.97038745880127,
      "learning_rate": 7.962900505902193e-05,
      "loss": 0.1035,
      "step": 7200
    },
    {
      "epoch": 1.0222657891051674,
      "grad_norm": 1.2008373737335205,
      "learning_rate": 7.850477796514897e-05,
      "loss": 0.0853,
      "step": 7300
    },
    {
      "epoch": 1.0362694300518134,
      "grad_norm": 4.306796073913574,
      "learning_rate": 7.7380550871276e-05,
      "loss": 0.1245,
      "step": 7400
    },
    {
      "epoch": 1.0502730709984596,
      "grad_norm": 0.04754889756441116,
      "learning_rate": 7.625632377740304e-05,
      "loss": 0.0922,
      "step": 7500
    },
    {
      "epoch": 1.0642767119451058,
      "grad_norm": 3.268958806991577,
      "learning_rate": 7.513209668353008e-05,
      "loss": 0.1168,
      "step": 7600
    },
    {
      "epoch": 1.078280352891752,
      "grad_norm": 0.5692768096923828,
      "learning_rate": 7.400786958965712e-05,
      "loss": 0.0929,
      "step": 7700
    },
    {
      "epoch": 1.092283993838398,
      "grad_norm": 4.585326671600342,
      "learning_rate": 7.288364249578416e-05,
      "loss": 0.0922,
      "step": 7800
    },
    {
      "epoch": 1.106287634785044,
      "grad_norm": 1.611642599105835,
      "learning_rate": 7.17594154019112e-05,
      "loss": 0.1015,
      "step": 7900
    },
    {
      "epoch": 1.1202912757316903,
      "grad_norm": 4.260227680206299,
      "learning_rate": 7.063518830803823e-05,
      "loss": 0.0865,
      "step": 8000
    },
    {
      "epoch": 1.1342949166783365,
      "grad_norm": 0.016007352620363235,
      "learning_rate": 6.951096121416527e-05,
      "loss": 0.0961,
      "step": 8100
    },
    {
      "epoch": 1.1482985576249825,
      "grad_norm": 0.037906404584646225,
      "learning_rate": 6.838673412029231e-05,
      "loss": 0.0759,
      "step": 8200
    },
    {
      "epoch": 1.1623021985716286,
      "grad_norm": 0.38209837675094604,
      "learning_rate": 6.726250702641934e-05,
      "loss": 0.0931,
      "step": 8300
    },
    {
      "epoch": 1.1763058395182748,
      "grad_norm": 4.1784586906433105,
      "learning_rate": 6.613827993254638e-05,
      "loss": 0.0984,
      "step": 8400
    },
    {
      "epoch": 1.1903094804649208,
      "grad_norm": 2.712172746658325,
      "learning_rate": 6.501405283867342e-05,
      "loss": 0.1015,
      "step": 8500
    },
    {
      "epoch": 1.204313121411567,
      "grad_norm": 1.9544214010238647,
      "learning_rate": 6.388982574480046e-05,
      "loss": 0.0853,
      "step": 8600
    },
    {
      "epoch": 1.2183167623582132,
      "grad_norm": 0.019992366433143616,
      "learning_rate": 6.276559865092748e-05,
      "loss": 0.0918,
      "step": 8700
    },
    {
      "epoch": 1.2323204033048594,
      "grad_norm": 0.13093268871307373,
      "learning_rate": 6.164137155705453e-05,
      "loss": 0.1019,
      "step": 8800
    },
    {
      "epoch": 1.2463240442515053,
      "grad_norm": 0.09811209887266159,
      "learning_rate": 6.051714446318157e-05,
      "loss": 0.0824,
      "step": 8900
    },
    {
      "epoch": 1.2603276851981515,
      "grad_norm": 0.07347311824560165,
      "learning_rate": 5.9392917369308606e-05,
      "loss": 0.0647,
      "step": 9000
    },
    {
      "epoch": 1.2743313261447977,
      "grad_norm": 0.7643862366676331,
      "learning_rate": 5.8268690275435646e-05,
      "loss": 0.1076,
      "step": 9100
    },
    {
      "epoch": 1.2883349670914437,
      "grad_norm": 11.547965049743652,
      "learning_rate": 5.714446318156268e-05,
      "loss": 0.1001,
      "step": 9200
    },
    {
      "epoch": 1.3023386080380899,
      "grad_norm": 0.24410396814346313,
      "learning_rate": 5.602023608768972e-05,
      "loss": 0.0996,
      "step": 9300
    },
    {
      "epoch": 1.316342248984736,
      "grad_norm": 0.38731977343559265,
      "learning_rate": 5.4896008993816757e-05,
      "loss": 0.1012,
      "step": 9400
    },
    {
      "epoch": 1.3303458899313823,
      "grad_norm": 2.6861114501953125,
      "learning_rate": 5.3771781899943796e-05,
      "loss": 0.0794,
      "step": 9500
    },
    {
      "epoch": 1.3443495308780282,
      "grad_norm": 1.7911354303359985,
      "learning_rate": 5.264755480607083e-05,
      "loss": 0.104,
      "step": 9600
    },
    {
      "epoch": 1.3583531718246744,
      "grad_norm": 0.18881678581237793,
      "learning_rate": 5.152332771219787e-05,
      "loss": 0.0984,
      "step": 9700
    },
    {
      "epoch": 1.3723568127713206,
      "grad_norm": 0.47003304958343506,
      "learning_rate": 5.039910061832491e-05,
      "loss": 0.0896,
      "step": 9800
    },
    {
      "epoch": 1.3863604537179666,
      "grad_norm": 4.099325656890869,
      "learning_rate": 4.9274873524451946e-05,
      "loss": 0.0981,
      "step": 9900
    },
    {
      "epoch": 1.4003640946646128,
      "grad_norm": 0.12659287452697754,
      "learning_rate": 4.8150646430578985e-05,
      "loss": 0.0776,
      "step": 10000
    },
    {
      "epoch": 1.414367735611259,
      "grad_norm": 0.15611110627651215,
      "learning_rate": 4.702641933670602e-05,
      "loss": 0.0928,
      "step": 10100
    },
    {
      "epoch": 1.4283713765579051,
      "grad_norm": 0.28840357065200806,
      "learning_rate": 4.590219224283306e-05,
      "loss": 0.0661,
      "step": 10200
    },
    {
      "epoch": 1.442375017504551,
      "grad_norm": 0.7845647931098938,
      "learning_rate": 4.4777965148960097e-05,
      "loss": 0.0671,
      "step": 10300
    },
    {
      "epoch": 1.4563786584511973,
      "grad_norm": 0.2898048460483551,
      "learning_rate": 4.3653738055087136e-05,
      "loss": 0.0766,
      "step": 10400
    },
    {
      "epoch": 1.4703822993978435,
      "grad_norm": 0.31756263971328735,
      "learning_rate": 4.252951096121416e-05,
      "loss": 0.0846,
      "step": 10500
    },
    {
      "epoch": 1.4843859403444895,
      "grad_norm": 0.5799064040184021,
      "learning_rate": 4.14052838673412e-05,
      "loss": 0.0858,
      "step": 10600
    },
    {
      "epoch": 1.4983895812911356,
      "grad_norm": 0.18434631824493408,
      "learning_rate": 4.028105677346824e-05,
      "loss": 0.06,
      "step": 10700
    },
    {
      "epoch": 1.5123932222377818,
      "grad_norm": 0.27527934312820435,
      "learning_rate": 3.9156829679595286e-05,
      "loss": 0.0856,
      "step": 10800
    },
    {
      "epoch": 1.526396863184428,
      "grad_norm": 7.206085681915283,
      "learning_rate": 3.803260258572232e-05,
      "loss": 0.0688,
      "step": 10900
    },
    {
      "epoch": 1.5404005041310742,
      "grad_norm": 3.797240972518921,
      "learning_rate": 3.690837549184936e-05,
      "loss": 0.0769,
      "step": 11000
    },
    {
      "epoch": 1.5544041450777202,
      "grad_norm": 4.138985633850098,
      "learning_rate": 3.578414839797639e-05,
      "loss": 0.0808,
      "step": 11100
    },
    {
      "epoch": 1.5684077860243664,
      "grad_norm": 0.30317509174346924,
      "learning_rate": 3.465992130410343e-05,
      "loss": 0.0742,
      "step": 11200
    },
    {
      "epoch": 1.5824114269710123,
      "grad_norm": 4.795144081115723,
      "learning_rate": 3.353569421023047e-05,
      "loss": 0.0863,
      "step": 11300
    },
    {
      "epoch": 1.5964150679176585,
      "grad_norm": 0.39654821157455444,
      "learning_rate": 3.241146711635751e-05,
      "loss": 0.0716,
      "step": 11400
    },
    {
      "epoch": 1.6104187088643047,
      "grad_norm": 0.17703324556350708,
      "learning_rate": 3.128724002248455e-05,
      "loss": 0.0606,
      "step": 11500
    },
    {
      "epoch": 1.624422349810951,
      "grad_norm": 1.0437729358673096,
      "learning_rate": 3.016301292861158e-05,
      "loss": 0.0654,
      "step": 11600
    },
    {
      "epoch": 1.638425990757597,
      "grad_norm": 3.4363105297088623,
      "learning_rate": 2.903878583473862e-05,
      "loss": 0.0806,
      "step": 11700
    },
    {
      "epoch": 1.652429631704243,
      "grad_norm": 0.10258838534355164,
      "learning_rate": 2.7914558740865655e-05,
      "loss": 0.0737,
      "step": 11800
    },
    {
      "epoch": 1.6664332726508893,
      "grad_norm": 5.934235572814941,
      "learning_rate": 2.6790331646992694e-05,
      "loss": 0.0915,
      "step": 11900
    },
    {
      "epoch": 1.6804369135975352,
      "grad_norm": 0.11080116033554077,
      "learning_rate": 2.566610455311973e-05,
      "loss": 0.0654,
      "step": 12000
    },
    {
      "epoch": 1.6944405545441814,
      "grad_norm": 2.4800376892089844,
      "learning_rate": 2.454187745924677e-05,
      "loss": 0.0607,
      "step": 12100
    },
    {
      "epoch": 1.7084441954908276,
      "grad_norm": 5.689997673034668,
      "learning_rate": 2.3417650365373805e-05,
      "loss": 0.049,
      "step": 12200
    },
    {
      "epoch": 1.7224478364374738,
      "grad_norm": 0.049884747713804245,
      "learning_rate": 2.2293423271500845e-05,
      "loss": 0.0605,
      "step": 12300
    },
    {
      "epoch": 1.73645147738412,
      "grad_norm": 3.2450103759765625,
      "learning_rate": 2.1169196177627884e-05,
      "loss": 0.0676,
      "step": 12400
    },
    {
      "epoch": 1.750455118330766,
      "grad_norm": 0.15003083646297455,
      "learning_rate": 2.004496908375492e-05,
      "loss": 0.0655,
      "step": 12500
    },
    {
      "epoch": 1.7644587592774121,
      "grad_norm": 1.6674840450286865,
      "learning_rate": 1.8920741989881956e-05,
      "loss": 0.0566,
      "step": 12600
    },
    {
      "epoch": 1.778462400224058,
      "grad_norm": 0.11016910523176193,
      "learning_rate": 1.7796514896008995e-05,
      "loss": 0.073,
      "step": 12700
    },
    {
      "epoch": 1.7924660411707043,
      "grad_norm": 0.40213361382484436,
      "learning_rate": 1.6672287802136034e-05,
      "loss": 0.0571,
      "step": 12800
    },
    {
      "epoch": 1.8064696821173505,
      "grad_norm": 0.16606619954109192,
      "learning_rate": 1.554806070826307e-05,
      "loss": 0.0716,
      "step": 12900
    },
    {
      "epoch": 1.8204733230639967,
      "grad_norm": 0.03122747503221035,
      "learning_rate": 1.4423833614390108e-05,
      "loss": 0.0428,
      "step": 13000
    },
    {
      "epoch": 1.8344769640106429,
      "grad_norm": 0.011275894939899445,
      "learning_rate": 1.3299606520517145e-05,
      "loss": 0.0578,
      "step": 13100
    },
    {
      "epoch": 1.848480604957289,
      "grad_norm": 0.010619663633406162,
      "learning_rate": 1.2175379426644183e-05,
      "loss": 0.0638,
      "step": 13200
    },
    {
      "epoch": 1.862484245903935,
      "grad_norm": 0.050868481397628784,
      "learning_rate": 1.105115233277122e-05,
      "loss": 0.0721,
      "step": 13300
    },
    {
      "epoch": 1.876487886850581,
      "grad_norm": 0.012708520516753197,
      "learning_rate": 9.926925238898258e-06,
      "loss": 0.0479,
      "step": 13400
    },
    {
      "epoch": 1.8904915277972272,
      "grad_norm": 0.023141831159591675,
      "learning_rate": 8.802698145025296e-06,
      "loss": 0.0515,
      "step": 13500
    },
    {
      "epoch": 1.9044951687438734,
      "grad_norm": 0.3822462260723114,
      "learning_rate": 7.678471051152333e-06,
      "loss": 0.0675,
      "step": 13600
    },
    {
      "epoch": 1.9184988096905196,
      "grad_norm": 0.20274300873279572,
      "learning_rate": 6.554243957279372e-06,
      "loss": 0.0642,
      "step": 13700
    },
    {
      "epoch": 1.9325024506371657,
      "grad_norm": 0.46521666646003723,
      "learning_rate": 5.4300168634064085e-06,
      "loss": 0.0718,
      "step": 13800
    },
    {
      "epoch": 1.946506091583812,
      "grad_norm": 0.2121821939945221,
      "learning_rate": 4.305789769533446e-06,
      "loss": 0.0696,
      "step": 13900
    },
    {
      "epoch": 1.960509732530458,
      "grad_norm": 0.01059445645660162,
      "learning_rate": 3.181562675660484e-06,
      "loss": 0.0559,
      "step": 14000
    },
    {
      "epoch": 1.974513373477104,
      "grad_norm": 0.15797287225723267,
      "learning_rate": 2.0573355817875212e-06,
      "loss": 0.049,
      "step": 14100
    },
    {
      "epoch": 1.98851701442375,
      "grad_norm": 2.218125343322754,
      "learning_rate": 9.331084879145588e-07,
      "loss": 0.0401,
      "step": 14200
    }
  ],
  "logging_steps": 100,
  "max_steps": 14282,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.770552477112121e+19,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
