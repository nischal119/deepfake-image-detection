{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DeepFake Detector Training Pipeline\n",
        "\n",
        "This notebook implements a complete deepfake detection training pipeline using Vision Transformer (ViT) model. The pipeline includes:\n",
        "\n",
        "1. **Dataset Setup**: Automatic dataset download and organization\n",
        "2. **Data Preprocessing**: Image loading, balancing, and augmentation\n",
        "3. **Model Training**: Fine-tuning ViT for deepfake detection\n",
        "4. **Evaluation**: Model performance assessment\n",
        "\n",
        "## Features\n",
        "- üöÄ **Automatic Dataset Management**: Downloads dataset from Kaggle in Colab, uses local dataset otherwise\n",
        "- ‚öñÔ∏è **Data Balancing**: Uses RandomOverSampler to handle class imbalance\n",
        "- üîÑ **Data Augmentation**: Random rotation and sharpness adjustment for training\n",
        "- ü§ñ **Vision Transformer**: Uses pre-trained ViT model for transfer learning\n",
        "- üìä **Comprehensive Evaluation**: Accuracy metrics and detailed logging\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Libraries and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gc\n",
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import time\n",
        "\n",
        "import evaluate\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from datasets import ClassLabel, Dataset, Image\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from PIL import ImageFile\n",
        "from torchvision.transforms import (\n",
        "    Compose,\n",
        "    Normalize,\n",
        "    RandomAdjustSharpness,\n",
        "    RandomRotation,\n",
        "    Resize,\n",
        "    ToTensor,\n",
        ")\n",
        "from tqdm import tqdm\n",
        "from transformers import (\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    ViTForImageClassification,\n",
        "    ViTImageProcessor,\n",
        ")\n",
        "\n",
        "# Allow loading truncated images\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Utility Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def in_colab() -> bool:\n",
        "    \"\"\"Check if running in Google Colab environment.\"\"\"\n",
        "    return \"google.colab\" in sys.modules\n",
        "\n",
        "print(\"‚úÖ Utility functions defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Dataset Management Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ensure_kaggle_dataset_colab(data_dir: Path) -> Path:\n",
        "    \"\"\"\n",
        "    In Colab: download and extract the dataset into data_dir.\n",
        "    Returns the extracted dataset root (data_dir / \"Dataset\").\n",
        "    \"\"\"\n",
        "    zip_path = data_dir / \"deepfake-and-real-images.zip\"\n",
        "    extracted_dir = data_dir / \"Dataset\"\n",
        "\n",
        "    data_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Install kaggle if missing\n",
        "    try:\n",
        "        subprocess.run(\n",
        "            [\"kaggle\", \"-h\"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL\n",
        "        )\n",
        "    except FileNotFoundError:\n",
        "        subprocess.check_call(\n",
        "            [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"kaggle\"]\n",
        "        )  # quiet install\n",
        "\n",
        "    # Prepare kaggle creds\n",
        "    kaggle_json_src = Path(\"/content/kaggle.json\")\n",
        "    kaggle_dir = Path(\"/root/.kaggle\")\n",
        "    if kaggle_json_src.exists():\n",
        "        kaggle_dir.mkdir(parents=True, exist_ok=True)\n",
        "        subprocess.check_call(\n",
        "            [\"cp\", str(kaggle_json_src), str(kaggle_dir / \"kaggle.json\")]\n",
        "        )\n",
        "        subprocess.check_call([\"chmod\", \"600\", str(kaggle_dir / \"kaggle.json\")])\n",
        "    else:\n",
        "        print(\n",
        "            \"kaggle.json not found at /content/kaggle.json. Skipping download; expecting dataset to be present.\"\n",
        "        )\n",
        "\n",
        "    if not zip_path.exists() and kaggle_json_src.exists():\n",
        "        print(\"Downloading dataset from Kaggle...\")\n",
        "        subprocess.check_call(\n",
        "            [\n",
        "                \"kaggle\",\n",
        "                \"datasets\",\n",
        "                \"download\",\n",
        "                \"manjilkarki/deepfake-and-real-images\",\n",
        "                \"-p\",\n",
        "                str(data_dir),\n",
        "                \"--force\",\n",
        "            ]\n",
        "        )\n",
        "    else:\n",
        "        print(\"Dataset zip already exists or kaggle.json missing; skipping download.\")\n",
        "\n",
        "    if not extracted_dir.exists() and zip_path.exists():\n",
        "        print(\"Extracting dataset zip...\")\n",
        "        subprocess.check_call([\"unzip\", \"-q\", str(zip_path), \"-d\", str(data_dir)])\n",
        "        print(\"Extraction completed.\")\n",
        "    else:\n",
        "        print(\"Dataset already extracted or zip missing.\")\n",
        "\n",
        "    return extracted_dir\n",
        "\n",
        "print(\"‚úÖ Dataset management functions defined!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def resolve_dataset_root() -> Path:\n",
        "    \"\"\"\n",
        "    - If running in Colab: ensure dataset exists under /content/deepfake_dataset and return its Dataset folder.\n",
        "    - Else: use local \"Dataset\" folder next to this script.\n",
        "    \"\"\"\n",
        "    if in_colab():\n",
        "        base = ensure_kaggle_dataset_colab(Path(\"/content/deepfake_dataset\"))\n",
        "        return base\n",
        "    # Local/non-Colab\n",
        "    local = Path(\"Dataset\")\n",
        "    if not local.exists():\n",
        "        raise FileNotFoundError(\n",
        "            f\"Dataset folder not found at {local.resolve()}. Place your dataset there (Train/Real, Train/Fake, etc.).\"\n",
        "        )\n",
        "    return local\n",
        "\n",
        "print(\"‚úÖ Dataset resolution function defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Data Processing Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_dataframe(base_path: Path) -> pd.DataFrame:\n",
        "    \"\"\"Build a pandas DataFrame from the dataset directory.\"\"\"\n",
        "    print(\"üîç Scanning dataset directory...\")\n",
        "    file_names, labels = [], []\n",
        "\n",
        "    # Get all jpg files first\n",
        "    all_files = list(base_path.rglob(\"*.jpg\"))\n",
        "    print(f\"üìÅ Found {len(all_files)} image files\")\n",
        "\n",
        "    # Process with progress bar\n",
        "    for file in tqdm(all_files, desc=\"üìä Building dataset\", unit=\"images\"):\n",
        "        labels.append(file.parent.name)\n",
        "        file_names.append(str(file))\n",
        "\n",
        "    df = pd.DataFrame({\"image\": file_names, \"label\": labels})\n",
        "    print(f\"‚úÖ Dataset created with {len(df)} images\")\n",
        "    print(f\"üìà Label distribution:\\n{df['label'].value_counts()}\")\n",
        "    return df\n",
        "\n",
        "print(\"‚úÖ Data processing functions defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Main Training Pipeline\n",
        "\n",
        "Now let's run the complete training pipeline step by step.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Dataset Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üöÄ Starting DeepFake Detector Training Pipeline\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Step 1: Dataset setup\n",
        "print(\"\\nüìÇ Step 1: Setting up dataset...\")\n",
        "dataset_root = resolve_dataset_root()\n",
        "print(f\"üìç Using dataset at: {dataset_root.resolve()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Build Dataset DataFrame\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 2: Build dataframe\n",
        "print(\"\\nüìä Step 2: Building dataset dataframe...\")\n",
        "df = build_dataframe(dataset_root)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Balance Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3: Balance dataset\n",
        "print(\"\\n‚öñÔ∏è  Step 3: Balancing dataset...\")\n",
        "print(\"üîÑ Applying RandomOverSampler...\")\n",
        "y = df[[\"label\"]]\n",
        "df_x = df.drop([\"label\"], axis=1)\n",
        "ros = RandomOverSampler(random_state=83)\n",
        "df_x, y_resampled = ros.fit_resample(df_x, y)\n",
        "df = df_x.copy()\n",
        "df[\"label\"] = y_resampled\n",
        "del y_resampled, df_x\n",
        "gc.collect()\n",
        "print(f\"‚úÖ Dataset balanced: {df.shape[0]} samples\")\n",
        "print(f\"üìà Balanced distribution:\\n{df['label'].value_counts()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: Create HuggingFace Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4: Create HuggingFace dataset\n",
        "print(\"\\nü§ó Step 4: Creating HuggingFace dataset...\")\n",
        "with tqdm(total=3, desc=\"üîÑ Processing dataset\") as pbar:\n",
        "    dataset = Dataset.from_pandas(df).cast_column(\"image\", Image())\n",
        "    pbar.update(1)\n",
        "\n",
        "    labels_list = [\"Real\", \"Fake\"]\n",
        "    label2id = {name: idx for idx, name in enumerate(labels_list)}\n",
        "    id2label = {idx: name for name, idx in label2id.items()}\n",
        "    pbar.update(1)\n",
        "\n",
        "    class_labels = ClassLabel(num_classes=len(labels_list), names=labels_list)\n",
        "\n",
        "    def map_label2id(example):\n",
        "        example[\"label\"] = class_labels.str2int(example[\"label\"])\n",
        "        return example\n",
        "\n",
        "    dataset = dataset.map(map_label2id, batched=True)\n",
        "    dataset = dataset.cast_column(\"label\", class_labels)\n",
        "    pbar.update(1)\n",
        "\n",
        "print(\"‚úÖ HuggingFace dataset created\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 5: Split Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 5: Split dataset\n",
        "print(\"\\n‚úÇÔ∏è  Step 5: Splitting dataset...\")\n",
        "print(\"üîÑ Creating train/test split (60/40)...\")\n",
        "dataset = dataset.train_test_split(\n",
        "    test_size=0.4, shuffle=True, stratify_by_column=\"label\"\n",
        ")\n",
        "train_data = dataset[\"train\"]\n",
        "test_data = dataset[\"test\"]\n",
        "\n",
        "print(f\"‚úÖ Split complete:\")\n",
        "print(f\"   üìö Training samples: {len(train_data)}\")\n",
        "print(f\"   üß™ Test samples: {len(test_data)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 6: Load Model and Processor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 6: Load model and processor\n",
        "print(\"\\nü§ñ Step 6: Loading model and processor...\")\n",
        "model_str = \"dima806/deepfake_vs_real_image_detection\"\n",
        "print(\"üîÑ Loading ViT processor...\")\n",
        "processor = ViTImageProcessor.from_pretrained(model_str)\n",
        "\n",
        "image_mean, image_std = processor.image_mean, processor.image_std\n",
        "size = processor.size[\"height\"]\n",
        "print(f\"üìè Image size: {size}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 7: Setup Image Transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 7: Setup transforms\n",
        "print(\"\\nüîÑ Step 7: Setting up image transforms...\")\n",
        "normalize = Normalize(mean=image_mean, std=image_std)\n",
        "\n",
        "_train_transforms = Compose(\n",
        "    [\n",
        "        Resize((size, size)),\n",
        "        RandomRotation(90),\n",
        "        RandomAdjustSharpness(2),\n",
        "        ToTensor(),\n",
        "        normalize,\n",
        "    ]\n",
        ")\n",
        "\n",
        "_val_transforms = Compose(\n",
        "    [\n",
        "        Resize((size, size)),\n",
        "        ToTensor(),\n",
        "        normalize,\n",
        "    ]\n",
        ")\n",
        "\n",
        "def train_transforms(examples):\n",
        "    if \"image\" not in examples:\n",
        "        return examples\n",
        "    examples[\"pixel_values\"] = [\n",
        "        _train_transforms(image.convert(\"RGB\")) for image in examples[\"image\"]\n",
        "    ]\n",
        "    return examples\n",
        "\n",
        "def val_transforms(examples):\n",
        "    if \"image\" not in examples:\n",
        "        return examples\n",
        "    examples[\"pixel_values\"] = [\n",
        "        _val_transforms(image.convert(\"RGB\")) for image in examples[\"image\"]\n",
        "    ]\n",
        "    return examples\n",
        "\n",
        "train_data.set_transform(train_transforms)\n",
        "test_data.set_transform(val_transforms)\n",
        "print(\"‚úÖ Transforms applied\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 8: Setup Model and Training Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 8: Setup model and training\n",
        "print(\"\\nüèóÔ∏è  Step 8: Setting up model and training...\")\n",
        "\n",
        "def collate_fn(examples):\n",
        "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
        "    labels = torch.tensor([example[\"label\"] for example in examples])\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
        "\n",
        "print(\"üîÑ Loading ViT model...\")\n",
        "model = ViTForImageClassification.from_pretrained(\n",
        "    model_str,\n",
        "    num_labels=2,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")\n",
        "print(\n",
        "    f\"‚úÖ Model loaded: {model.num_parameters(only_trainable=True)/1e6:.1f}M parameters\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üîÑ Setting up metrics...\")\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions = eval_pred.predictions\n",
        "    label_ids = eval_pred.label_ids\n",
        "    preds = predictions.argmax(axis=1)\n",
        "    return {\n",
        "        \"accuracy\": metric.compute(predictions=preds, references=label_ids)[\n",
        "            \"accuracy\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "print(\"üîÑ Configuring training arguments...\")\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"deepfake_vs_real_image_detection\",\n",
        "    logging_dir=\"./logs\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=2,\n",
        "    learning_rate=1.6e-4,\n",
        "    weight_decay=0.02,\n",
        "    warmup_steps=50,\n",
        "    save_total_limit=1,\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    report_to=\"none\",\n",
        "    logging_steps=100,\n",
        "    remove_unused_columns=False,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üîÑ Creating trainer...\")\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=test_data,\n",
        "    data_collator=collate_fn,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "print(\"‚úÖ Trainer ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 9: Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 9: Training\n",
        "print(\"\\nüéØ Step 9: Starting training...\")\n",
        "print(\"üî• Training for 2 epochs...\")\n",
        "trainer.train()\n",
        "print(\"‚úÖ Training completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 10: Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 10: Evaluation\n",
        "print(\"\\nüìä Step 10: Evaluating model...\")\n",
        "results = trainer.evaluate()\n",
        "print(\"üéâ Final Results:\")\n",
        "for key, value in results.items():\n",
        "    print(f\"   {key}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model Inference (Optional)\n",
        "\n",
        "You can use the trained model for inference on new images. Here's an example:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_image(image_path, model, processor):\n",
        "    \"\"\"Predict if an image is real or fake.\"\"\"\n",
        "    from PIL import Image\n",
        "    \n",
        "    # Load and preprocess image\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    inputs = processor(images=image, return_tensors=\"pt\")\n",
        "    \n",
        "    # Make prediction\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "        predicted_class_id = predictions.argmax().item()\n",
        "        confidence = predictions[0][predicted_class_id].item()\n",
        "    \n",
        "    # Get class name\n",
        "    class_name = model.config.id2label[predicted_class_id]\n",
        "    \n",
        "    return class_name, confidence\n",
        "\n",
        "# Example usage (uncomment to test):\n",
        "# image_path = \"path/to/your/test/image.jpg\"\n",
        "# prediction, confidence = predict_image(image_path, model, processor)\n",
        "# print(f\"Prediction: {prediction} (Confidence: {confidence:.2f})\")\n",
        "\n",
        "print(\"‚úÖ Inference function defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Summary\n",
        "\n",
        "This notebook provides a complete deepfake detection training pipeline with the following key features:\n",
        "\n",
        "### ‚úÖ **Completed Steps:**\n",
        "1. **Dataset Management**: Automatic download from Kaggle (Colab) or local dataset usage\n",
        "2. **Data Preprocessing**: Image loading, balancing with RandomOverSampler\n",
        "3. **Model Setup**: Vision Transformer (ViT) with pre-trained weights\n",
        "4. **Training Configuration**: Optimized hyperparameters for deepfake detection\n",
        "5. **Data Augmentation**: Random rotation and sharpness adjustment\n",
        "6. **Model Training**: 2 epochs with comprehensive logging\n",
        "7. **Evaluation**: Accuracy metrics and performance assessment\n",
        "8. **Inference**: Ready-to-use prediction function\n",
        "\n",
        "### üéØ **Key Features:**\n",
        "- **Automatic Environment Detection**: Works in both Colab and local environments\n",
        "- **Data Balancing**: Handles class imbalance with RandomOverSampler\n",
        "- **Transfer Learning**: Uses pre-trained ViT model for better performance\n",
        "- **Comprehensive Logging**: Detailed progress tracking with emojis and progress bars\n",
        "- **Memory Management**: Proper garbage collection and memory optimization\n",
        "\n",
        "### üìä **Expected Results:**\n",
        "- Training accuracy should improve over epochs\n",
        "- Final evaluation will show model performance on test set\n",
        "- Model can be used for inference on new images\n",
        "\n",
        "### üöÄ **Next Steps:**\n",
        "- Run all cells sequentially to train the model\n",
        "- Adjust hyperparameters if needed\n",
        "- Use the inference function to test on new images\n",
        "- Save the trained model for future use\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
