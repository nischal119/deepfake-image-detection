{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DeepFake Detector Training Pipeline\n",
        "\n",
        "This notebook implements a complete deepfake detection training pipeline using Vision Transformer (ViT) model. The pipeline includes:\n",
        "\n",
        "1. **Dataset Setup**: Automatic dataset download and organization\n",
        "2. **Data Preprocessing**: Image loading, balancing, and augmentation\n",
        "3. **Model Training**: Fine-tuning ViT for deepfake detection\n",
        "4. **Evaluation**: Model performance assessment\n",
        "\n",
        "## Features\n",
        "- 🚀 **Automatic Dataset Management**: Downloads dataset from Kaggle in Colab, uses local dataset otherwise\n",
        "- ⚖️ **Data Balancing**: Uses RandomOverSampler to handle class imbalance\n",
        "- 🔄 **Data Augmentation**: Random rotation and sharpness adjustment for training\n",
        "- 🤖 **Vision Transformer**: Uses pre-trained ViT model for transfer learning\n",
        "- 📊 **Comprehensive Evaluation**: Accuracy metrics and detailed logging\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Libraries and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gc\n",
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import time\n",
        "\n",
        "import evaluate\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from datasets import ClassLabel, Dataset, Image\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from PIL import ImageFile\n",
        "from torchvision.transforms import (\n",
        "    Compose,\n",
        "    Normalize,\n",
        "    RandomAdjustSharpness,\n",
        "    RandomRotation,\n",
        "    Resize,\n",
        "    ToTensor,\n",
        ")\n",
        "from tqdm import tqdm\n",
        "from transformers import (\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    ViTForImageClassification,\n",
        "    ViTImageProcessor,\n",
        ")\n",
        "\n",
        "# Allow loading truncated images\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "print(\"✅ All libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Utility Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def in_colab() -> bool:\n",
        "    \"\"\"Check if running in Google Colab environment.\"\"\"\n",
        "    return \"google.colab\" in sys.modules\n",
        "\n",
        "print(\"✅ Utility functions defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Dataset Management Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ensure_kaggle_dataset_colab(data_dir: Path) -> Path:\n",
        "    \"\"\"\n",
        "    In Colab: download and extract the dataset into data_dir.\n",
        "    Returns the extracted dataset root (data_dir / \"Dataset\").\n",
        "    \"\"\"\n",
        "    zip_path = data_dir / \"deepfake-and-real-images.zip\"\n",
        "    extracted_dir = data_dir / \"Dataset\"\n",
        "\n",
        "    data_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Install kaggle if missing\n",
        "    try:\n",
        "        subprocess.run(\n",
        "            [\"kaggle\", \"-h\"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL\n",
        "        )\n",
        "    except FileNotFoundError:\n",
        "        subprocess.check_call(\n",
        "            [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"kaggle\"]\n",
        "        )  # quiet install\n",
        "\n",
        "    # Prepare kaggle creds\n",
        "    kaggle_json_src = Path(\"/content/kaggle.json\")\n",
        "    kaggle_dir = Path(\"/root/.kaggle\")\n",
        "    if kaggle_json_src.exists():\n",
        "        kaggle_dir.mkdir(parents=True, exist_ok=True)\n",
        "        subprocess.check_call(\n",
        "            [\"cp\", str(kaggle_json_src), str(kaggle_dir / \"kaggle.json\")]\n",
        "        )\n",
        "        subprocess.check_call([\"chmod\", \"600\", str(kaggle_dir / \"kaggle.json\")])\n",
        "    else:\n",
        "        print(\n",
        "            \"kaggle.json not found at /content/kaggle.json. Skipping download; expecting dataset to be present.\"\n",
        "        )\n",
        "\n",
        "    if not zip_path.exists() and kaggle_json_src.exists():\n",
        "        print(\"Downloading dataset from Kaggle...\")\n",
        "        subprocess.check_call(\n",
        "            [\n",
        "                \"kaggle\",\n",
        "                \"datasets\",\n",
        "                \"download\",\n",
        "                \"manjilkarki/deepfake-and-real-images\",\n",
        "                \"-p\",\n",
        "                str(data_dir),\n",
        "                \"--force\",\n",
        "            ]\n",
        "        )\n",
        "    else:\n",
        "        print(\"Dataset zip already exists or kaggle.json missing; skipping download.\")\n",
        "\n",
        "    if not extracted_dir.exists() and zip_path.exists():\n",
        "        print(\"Extracting dataset zip...\")\n",
        "        subprocess.check_call([\"unzip\", \"-q\", str(zip_path), \"-d\", str(data_dir)])\n",
        "        print(\"Extraction completed.\")\n",
        "    else:\n",
        "        print(\"Dataset already extracted or zip missing.\")\n",
        "\n",
        "    return extracted_dir\n",
        "\n",
        "print(\"✅ Dataset management functions defined!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def resolve_dataset_root() -> Path:\n",
        "    \"\"\"\n",
        "    - If running in Colab: ensure dataset exists under /content/deepfake_dataset and return its Dataset folder.\n",
        "    - Else: use local \"Dataset\" folder next to this script.\n",
        "    \"\"\"\n",
        "    if in_colab():\n",
        "        base = ensure_kaggle_dataset_colab(Path(\"/content/deepfake_dataset\"))\n",
        "        return base\n",
        "    # Local/non-Colab\n",
        "    local = Path(\"Dataset\")\n",
        "    if not local.exists():\n",
        "        raise FileNotFoundError(\n",
        "            f\"Dataset folder not found at {local.resolve()}. Place your dataset there (Train/Real, Train/Fake, etc.).\"\n",
        "        )\n",
        "    return local\n",
        "\n",
        "print(\"✅ Dataset resolution function defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Data Processing Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_dataframe(base_path: Path) -> pd.DataFrame:\n",
        "    \"\"\"Build a pandas DataFrame from the dataset directory.\"\"\"\n",
        "    print(\"🔍 Scanning dataset directory...\")\n",
        "    file_names, labels = [], []\n",
        "\n",
        "    # Get all jpg files first\n",
        "    all_files = list(base_path.rglob(\"*.jpg\"))\n",
        "    print(f\"📁 Found {len(all_files)} image files\")\n",
        "\n",
        "    # Process with progress bar\n",
        "    for file in tqdm(all_files, desc=\"📊 Building dataset\", unit=\"images\"):\n",
        "        labels.append(file.parent.name)\n",
        "        file_names.append(str(file))\n",
        "\n",
        "    df = pd.DataFrame({\"image\": file_names, \"label\": labels})\n",
        "    print(f\"✅ Dataset created with {len(df)} images\")\n",
        "    print(f\"📈 Label distribution:\\n{df['label'].value_counts()}\")\n",
        "    return df\n",
        "\n",
        "print(\"✅ Data processing functions defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Main Training Pipeline\n",
        "\n",
        "Now let's run the complete training pipeline step by step.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Dataset Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"🚀 Starting DeepFake Detector Training Pipeline\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Step 1: Dataset setup\n",
        "print(\"\\n📂 Step 1: Setting up dataset...\")\n",
        "dataset_root = resolve_dataset_root()\n",
        "print(f\"📍 Using dataset at: {dataset_root.resolve()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Build Dataset DataFrame\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 2: Build dataframe\n",
        "print(\"\\n📊 Step 2: Building dataset dataframe...\")\n",
        "df = build_dataframe(dataset_root)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Balance Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3: Balance dataset\n",
        "print(\"\\n⚖️  Step 3: Balancing dataset...\")\n",
        "print(\"🔄 Applying RandomOverSampler...\")\n",
        "y = df[[\"label\"]]\n",
        "df_x = df.drop([\"label\"], axis=1)\n",
        "ros = RandomOverSampler(random_state=83)\n",
        "df_x, y_resampled = ros.fit_resample(df_x, y)\n",
        "df = df_x.copy()\n",
        "df[\"label\"] = y_resampled\n",
        "del y_resampled, df_x\n",
        "gc.collect()\n",
        "print(f\"✅ Dataset balanced: {df.shape[0]} samples\")\n",
        "print(f\"📈 Balanced distribution:\\n{df['label'].value_counts()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: Create HuggingFace Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4: Create HuggingFace dataset\n",
        "print(\"\\n🤗 Step 4: Creating HuggingFace dataset...\")\n",
        "with tqdm(total=3, desc=\"🔄 Processing dataset\") as pbar:\n",
        "    dataset = Dataset.from_pandas(df).cast_column(\"image\", Image())\n",
        "    pbar.update(1)\n",
        "\n",
        "    labels_list = [\"Real\", \"Fake\"]\n",
        "    label2id = {name: idx for idx, name in enumerate(labels_list)}\n",
        "    id2label = {idx: name for name, idx in label2id.items()}\n",
        "    pbar.update(1)\n",
        "\n",
        "    class_labels = ClassLabel(num_classes=len(labels_list), names=labels_list)\n",
        "\n",
        "    def map_label2id(example):\n",
        "        example[\"label\"] = class_labels.str2int(example[\"label\"])\n",
        "        return example\n",
        "\n",
        "    dataset = dataset.map(map_label2id, batched=True)\n",
        "    dataset = dataset.cast_column(\"label\", class_labels)\n",
        "    pbar.update(1)\n",
        "\n",
        "print(\"✅ HuggingFace dataset created\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 5: Split Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 5: Split dataset\n",
        "print(\"\\n✂️  Step 5: Splitting dataset...\")\n",
        "print(\"🔄 Creating train/test split (60/40)...\")\n",
        "dataset = dataset.train_test_split(\n",
        "    test_size=0.4, shuffle=True, stratify_by_column=\"label\"\n",
        ")\n",
        "train_data = dataset[\"train\"]\n",
        "test_data = dataset[\"test\"]\n",
        "\n",
        "print(f\"✅ Split complete:\")\n",
        "print(f\"   📚 Training samples: {len(train_data)}\")\n",
        "print(f\"   🧪 Test samples: {len(test_data)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 6: Load Model and Processor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 6: Load model and processor\n",
        "print(\"\\n🤖 Step 6: Loading model and processor...\")\n",
        "model_str = \"dima806/deepfake_vs_real_image_detection\"\n",
        "print(\"🔄 Loading ViT processor...\")\n",
        "processor = ViTImageProcessor.from_pretrained(model_str)\n",
        "\n",
        "image_mean, image_std = processor.image_mean, processor.image_std\n",
        "size = processor.size[\"height\"]\n",
        "print(f\"📏 Image size: {size}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 7: Setup Image Transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 7: Setup transforms\n",
        "print(\"\\n🔄 Step 7: Setting up image transforms...\")\n",
        "normalize = Normalize(mean=image_mean, std=image_std)\n",
        "\n",
        "_train_transforms = Compose(\n",
        "    [\n",
        "        Resize((size, size)),\n",
        "        RandomRotation(90),\n",
        "        RandomAdjustSharpness(2),\n",
        "        ToTensor(),\n",
        "        normalize,\n",
        "    ]\n",
        ")\n",
        "\n",
        "_val_transforms = Compose(\n",
        "    [\n",
        "        Resize((size, size)),\n",
        "        ToTensor(),\n",
        "        normalize,\n",
        "    ]\n",
        ")\n",
        "\n",
        "def train_transforms(examples):\n",
        "    if \"image\" not in examples:\n",
        "        return examples\n",
        "    examples[\"pixel_values\"] = [\n",
        "        _train_transforms(image.convert(\"RGB\")) for image in examples[\"image\"]\n",
        "    ]\n",
        "    return examples\n",
        "\n",
        "def val_transforms(examples):\n",
        "    if \"image\" not in examples:\n",
        "        return examples\n",
        "    examples[\"pixel_values\"] = [\n",
        "        _val_transforms(image.convert(\"RGB\")) for image in examples[\"image\"]\n",
        "    ]\n",
        "    return examples\n",
        "\n",
        "train_data.set_transform(train_transforms)\n",
        "test_data.set_transform(val_transforms)\n",
        "print(\"✅ Transforms applied\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 8: Setup Model and Training Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 8: Setup model and training\n",
        "print(\"\\n🏗️  Step 8: Setting up model and training...\")\n",
        "\n",
        "def collate_fn(examples):\n",
        "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
        "    labels = torch.tensor([example[\"label\"] for example in examples])\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
        "\n",
        "print(\"🔄 Loading ViT model...\")\n",
        "model = ViTForImageClassification.from_pretrained(\n",
        "    model_str,\n",
        "    num_labels=2,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")\n",
        "print(\n",
        "    f\"✅ Model loaded: {model.num_parameters(only_trainable=True)/1e6:.1f}M parameters\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"🔄 Setting up metrics...\")\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions = eval_pred.predictions\n",
        "    label_ids = eval_pred.label_ids\n",
        "    preds = predictions.argmax(axis=1)\n",
        "    return {\n",
        "        \"accuracy\": metric.compute(predictions=preds, references=label_ids)[\n",
        "            \"accuracy\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "print(\"🔄 Configuring training arguments...\")\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"deepfake_vs_real_image_detection\",\n",
        "    logging_dir=\"./logs\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=2,\n",
        "    learning_rate=1.6e-4,\n",
        "    weight_decay=0.02,\n",
        "    warmup_steps=50,\n",
        "    save_total_limit=1,\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    report_to=\"none\",\n",
        "    logging_steps=100,\n",
        "    remove_unused_columns=False,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"🔄 Creating trainer...\")\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=test_data,\n",
        "    data_collator=collate_fn,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "print(\"✅ Trainer ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 9: Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 9: Training\n",
        "print(\"\\n🎯 Step 9: Starting training...\")\n",
        "print(\"🔥 Training for 2 epochs...\")\n",
        "trainer.train()\n",
        "print(\"✅ Training completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 10: Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 10: Evaluation\n",
        "print(\"\\n📊 Step 10: Evaluating model...\")\n",
        "results = trainer.evaluate()\n",
        "print(\"🎉 Final Results:\")\n",
        "for key, value in results.items():\n",
        "    print(f\"   {key}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model Inference (Optional)\n",
        "\n",
        "You can use the trained model for inference on new images. Here's an example:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_image(image_path, model, processor):\n",
        "    \"\"\"Predict if an image is real or fake.\"\"\"\n",
        "    from PIL import Image\n",
        "    \n",
        "    # Load and preprocess image\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    inputs = processor(images=image, return_tensors=\"pt\")\n",
        "    \n",
        "    # Make prediction\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "        predicted_class_id = predictions.argmax().item()\n",
        "        confidence = predictions[0][predicted_class_id].item()\n",
        "    \n",
        "    # Get class name\n",
        "    class_name = model.config.id2label[predicted_class_id]\n",
        "    \n",
        "    return class_name, confidence\n",
        "\n",
        "# Example usage (uncomment to test):\n",
        "# image_path = \"path/to/your/test/image.jpg\"\n",
        "# prediction, confidence = predict_image(image_path, model, processor)\n",
        "# print(f\"Prediction: {prediction} (Confidence: {confidence:.2f})\")\n",
        "\n",
        "print(\"✅ Inference function defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Summary\n",
        "\n",
        "This notebook provides a complete deepfake detection training pipeline with the following key features:\n",
        "\n",
        "### ✅ **Completed Steps:**\n",
        "1. **Dataset Management**: Automatic download from Kaggle (Colab) or local dataset usage\n",
        "2. **Data Preprocessing**: Image loading, balancing with RandomOverSampler\n",
        "3. **Model Setup**: Vision Transformer (ViT) with pre-trained weights\n",
        "4. **Training Configuration**: Optimized hyperparameters for deepfake detection\n",
        "5. **Data Augmentation**: Random rotation and sharpness adjustment\n",
        "6. **Model Training**: 2 epochs with comprehensive logging\n",
        "7. **Evaluation**: Accuracy metrics and performance assessment\n",
        "8. **Inference**: Ready-to-use prediction function\n",
        "\n",
        "### 🎯 **Key Features:**\n",
        "- **Automatic Environment Detection**: Works in both Colab and local environments\n",
        "- **Data Balancing**: Handles class imbalance with RandomOverSampler\n",
        "- **Transfer Learning**: Uses pre-trained ViT model for better performance\n",
        "- **Comprehensive Logging**: Detailed progress tracking with emojis and progress bars\n",
        "- **Memory Management**: Proper garbage collection and memory optimization\n",
        "\n",
        "### 📊 **Expected Results:**\n",
        "- Training accuracy should improve over epochs\n",
        "- Final evaluation will show model performance on test set\n",
        "- Model can be used for inference on new images\n",
        "\n",
        "### 🚀 **Next Steps:**\n",
        "- Run all cells sequentially to train the model\n",
        "- Adjust hyperparameters if needed\n",
        "- Use the inference function to test on new images\n",
        "- Save the trained model for future use\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
